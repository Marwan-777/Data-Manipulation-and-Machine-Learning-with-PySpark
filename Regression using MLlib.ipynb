{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVK9q1wr4DsU"
      },
      "source": [
        "# Regression in PySpark's MLlib Project\n",
        "\n",
        "Now it's time to put what you've learned to into action with a REAL project! \n",
        "\n",
        "You have been hired as a consultant to a cement production company who wants to be able to improve their customer experience around a number of areas like being able to provide recommendations to cusomters on optimal amounts of certian ingredients in the cement making process and perhaps even create an application where users can input their own values and received a predicted cement strength!\n",
        "\n",
        "I have provided a list of question below to help guide you through this project but feel free to deviate and make this project your own! But first, a bit about this dataset.\n",
        "\n",
        "### About this dataset \n",
        "This dataset contains 1030 instances of concrete samples, containing 9 attributes (8 continuous and 1 discreate), and 1 continuous quantitative output variable. There are no missing attribute values.\n",
        "\n",
        "I've also provided the variable name, variable type, the measurement unit and a brief description of each variable in the dataset. The concrete compressive strength is the outcome variable for our analysis. The order of this listing corresponds to the order of numerals along the rows of the database.\n",
        "\n",
        "Name -- Data Type -- Measurement -- Description\n",
        "\n",
        "- Cement -- quantitative -- kg in a m3 mixture -- Input Variable \n",
        "- Blast Furnace Slag -- quantitative -- kg in a m3 mixture -- Input Variable \n",
        "- Fly Ash -- quantitative -- kg in a m3 mixture -- Input Variable \n",
        "- Water -- quantitative -- kg in a m3 mixture -- Input Variable \n",
        "- Superplasticizer -- quantitative -- kg in a m3 mixture -- Input Variable \n",
        "- Coarse Aggregate -- quantitative -- kg in a m3 mixture -- Input Variable \n",
        "- Fine Aggregate -- quantitative -- kg in a m3 mixture -- Input Variable \n",
        "- Age -- quantitative -- Day (1~365) -- Input Variable \n",
        "- Concrete compressive strength -- quantitative -- MPa -- Output Variable\n",
        "\n",
        "**Source:** https://www.kaggle.com/maajdl/yeh-concret-data\n",
        "\n",
        "**Dataset Name:** Concrete_Data.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyS36aaB4Dse"
      },
      "source": [
        "## 1. Which features are the strongest predictors of cement strength?\n",
        "\n",
        "Build your own ML model to figure this one out! This would be good information to give to our client so the sales reps can focus their efforts on certian ingredients to provide recommendations on. For example, if our clients had a customer that was struggling with their cement breaking, we could trouble shoot with them by starting with the factors that we know are important. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eh-Cwq2G4Dsf"
      },
      "source": [
        "## 2. For the following given inputs, what would be the estimated cement strength?\n",
        "\n",
        "- Cement: 540\n",
        "- Blast Furnace Slag: 0\n",
        "- Fly Ash: 0\n",
        "- Water: 162\n",
        "- Superplasticizer: 2.5\n",
        "- Coarse Aggregate: 1040\n",
        "- Fine Aggregate: 676\n",
        "- Age: 28\n",
        "\n",
        "The correct answer is 79.99. Let's how close your prediction is!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTVh9nWi4Dsh"
      },
      "source": [
        "## 3. Now see if you can ask users to input their own value for Age and return a predicted value for the cement stength. \n",
        "\n",
        "We did not cover this is in the lecture so you'll have to put your thinking cap on. Accepting user input in PySpark works just like it does in traditional Python.\n",
        "<br>\n",
        "\n",
        "val = input(\"Enter your value: \") "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "933m62bo4Dsi"
      },
      "source": [
        "## 4. Make recommendations of optimal values for cement ingredients (our features)\n",
        "\n",
        "See if you can find the optimal amount of cement to recommend holding the rest of the values from the previous question constant, assuming that the higher the cement strength value the better. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "y8AfITxf_XDx",
        "outputId": "97293016-7681-4ed1-c49b-162e7cbeed62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.2.tar.gz (281.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 KB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.2-py2.py3-none-any.whl size=281824025 sha256=d57e36b53844d6e22fda6345a3cd2d1f238346f15f10957f8be4abcee5e535f7\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/59/a0/a1a0624b5e865fd389919c1a10f53aec9b12195d6747710baf\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.2\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f2d88b520d0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://25c09019f088:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.3.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>NLP</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "\n",
        "import pyspark # only run after findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "# May take awhile locally\n",
        "spark = SparkSession.builder.appName(\"NLP\").getOrCreate()\n",
        "\n",
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N4ihwtzC_XD_"
      },
      "outputs": [],
      "source": [
        "# For data prep\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.sql.types import * \n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "\n",
        "# To check for multicolinearity\n",
        "from pyspark.ml.stat import Correlation\n",
        "\n",
        "# For training and evaluation\n",
        "from pyspark.ml.regression import *\n",
        "from pyspark.ml.evaluation import *\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95gKJFl0_fca",
        "outputId": "7e1f5ab6-e113-406e-b337-4ec8f45dac4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gzbg-862_XEF"
      },
      "outputs": [],
      "source": [
        "path =\"drive/MyDrive/5. Spark/spark-scripts/section3/Datasets/\"\n",
        "\n",
        "df = spark.read.csv(path+'Concrete_Data.csv',inferSchema=True,header=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YadiBKBJKHvH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a902b49-26aa-41bb-e6f6-3b799535d366"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+------+-----+----------------+---------------+-------------+---+-----+\n",
            "|cement|slag |flyash|water|superplasticizer|coarseaggregate|fineaggregate|age|csMPa|\n",
            "+------+-----+------+-----+----------------+---------------+-------------+---+-----+\n",
            "|540.0 |0.0  |0.0   |162.0|2.5             |1040.0         |676.0        |28 |79.99|\n",
            "|540.0 |0.0  |0.0   |162.0|2.5             |1055.0         |676.0        |28 |61.89|\n",
            "|332.5 |142.5|0.0   |228.0|0.0             |932.0          |594.0        |270|40.27|\n",
            "|332.5 |142.5|0.0   |228.0|0.0             |932.0          |594.0        |365|41.05|\n",
            "|198.6 |132.4|0.0   |192.0|0.0             |978.4          |825.5        |360|44.3 |\n",
            "+------+-----+------+-----+----------------+---------------+-------------+---+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.show(5,truncate = False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print( 'Number of null values ', df.na.drop().count()-df.count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zlrgo9Gg9rGl",
        "outputId": "8b7d2d04-8c22-48ea-e188-9431c19248bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of null values  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.withColumnRenamed('csMPa','label')\n",
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCquq7kiWAfx",
        "outputId": "d1e8a38a-c114-48a5-bdd3-14fc078661e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- cement: double (nullable = true)\n",
            " |-- slag: double (nullable = true)\n",
            " |-- flyash: double (nullable = true)\n",
            " |-- water: double (nullable = true)\n",
            " |-- superplasticizer: double (nullable = true)\n",
            " |-- coarseaggregate: double (nullable = true)\n",
            " |-- fineaggregate: double (nullable = true)\n",
            " |-- age: integer (nullable = true)\n",
            " |-- label: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_features = df.columns[:-1]"
      ],
      "metadata": {
        "id": "KMbh-mXPWgFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "d = {}\n",
        "\n",
        "for col in input_features: \n",
        "    d[col] = df.approxQuantile(col,[0.01,0.99],0.25) #if you want to make it go faster increase the last number\n",
        "#Now fill in the values\n",
        "for col in input_features:\n",
        "    skew = df.agg(skewness(df[col])).collect() #check for skewness\n",
        "    skew = skew[0][0]\n",
        "    # This function will floor, cap and then log+1 (just in case there are 0 values)\n",
        "    if skew > 1:\n",
        "        df = df.withColumn(col, \\\n",
        "        log(when(df[col] < d[col][0],d[col][0])\\\n",
        "        .when(df[col] > d[col][1], d[col][1])\\\n",
        "        .otherwise(df[col] ) +1).alias(col))\n",
        "        print(col+\" has been treated for positive (right) skewness. (skew =)\",skew,\")\")\n",
        "    elif skew < -1:\n",
        "        df = df.withColumn(col, \\\n",
        "        exp(when(df[col] < d[col][0],d[col][0])\\\n",
        "        .when(df[col] > d[col][1], d[col][1])\\\n",
        "        .otherwise(df[col] )).alias(col))\n",
        "        print(col+\" has been treated for negative (left) skewness. (skew =\",skew,\")\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gu1PbZ5VZrs",
        "outputId": "b916fe22-fd69-4a01-aca5-86dbb6f079d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "age has been treated for positive (right) skewness. (skew =) 3.2644145354168086 )\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assembler = VectorAssembler(inputCols=input_features,outputCol='features')\n",
        "final_data = assembler.transform(df).select('features','label')"
      ],
      "metadata": {
        "id": "Xo27J5r-VeqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_data.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwL-yEb_X1bq",
        "outputId": "0cab532e-62b1-4bb0-fde9-c0a2c8ce8d9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+\n",
            "|            features|label|\n",
            "+--------------------+-----+\n",
            "|[540.0,0.0,0.0,16...|79.99|\n",
            "|[540.0,0.0,0.0,16...|61.89|\n",
            "|[332.5,142.5,0.0,...|40.27|\n",
            "|[332.5,142.5,0.0,...|41.05|\n",
            "|[198.6,132.4,0.0,...| 44.3|\n",
            "+--------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pearsonCorr = Correlation.corr(final_data, 'features', 'pearson').collect()[0][0]\n",
        "array = pearsonCorr.toArray()"
      ],
      "metadata": {
        "id": "1Ta5gGXFX15y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "i = 0\n",
        "corrList = []\n",
        "for item in array:\n",
        "    innerList = []\n",
        "    innerList.append(input_features[i])\n",
        "    for innerItem in item:\n",
        "      innerList.append(str(numpy.round(innerItem,3)))\n",
        "    corrList.append(innerList)\n",
        "    i = i + 1\n",
        "corrData = spark.createDataFrame(data = corrList,schema = ['0']+input_features)\n",
        "corrData.limit(10).toPandas()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "gHLfeiMGYNSV",
        "outputId": "8819af42-f0dd-44f1-9018-4148a1868324"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  0  cement    slag  flyash   water superplasticizer  \\\n",
              "0            cement     1.0  -0.275  -0.397  -0.082            0.092   \n",
              "1              slag  -0.275     1.0  -0.324   0.107            0.043   \n",
              "2            flyash  -0.397  -0.324     1.0  -0.257            0.378   \n",
              "3             water  -0.082   0.107  -0.257     1.0           -0.658   \n",
              "4  superplasticizer   0.092   0.043   0.378  -0.658              1.0   \n",
              "5   coarseaggregate  -0.109  -0.284   -0.01  -0.182           -0.266   \n",
              "6     fineaggregate  -0.223  -0.282   0.079  -0.451            0.223   \n",
              "7               age   0.003  -0.021   -0.02    0.17           -0.048   \n",
              "\n",
              "  coarseaggregate fineaggregate     age  \n",
              "0          -0.109        -0.223   0.003  \n",
              "1          -0.284        -0.282  -0.021  \n",
              "2           -0.01         0.079   -0.02  \n",
              "3          -0.182        -0.451    0.17  \n",
              "4          -0.266         0.223  -0.048  \n",
              "5             1.0        -0.178  -0.038  \n",
              "6          -0.178           1.0  -0.115  \n",
              "7          -0.038        -0.115     1.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ff6531e9-59ae-4cee-b7f0-cf6f69fda985\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>cement</th>\n",
              "      <th>slag</th>\n",
              "      <th>flyash</th>\n",
              "      <th>water</th>\n",
              "      <th>superplasticizer</th>\n",
              "      <th>coarseaggregate</th>\n",
              "      <th>fineaggregate</th>\n",
              "      <th>age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cement</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.275</td>\n",
              "      <td>-0.397</td>\n",
              "      <td>-0.082</td>\n",
              "      <td>0.092</td>\n",
              "      <td>-0.109</td>\n",
              "      <td>-0.223</td>\n",
              "      <td>0.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>slag</td>\n",
              "      <td>-0.275</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.324</td>\n",
              "      <td>0.107</td>\n",
              "      <td>0.043</td>\n",
              "      <td>-0.284</td>\n",
              "      <td>-0.282</td>\n",
              "      <td>-0.021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>flyash</td>\n",
              "      <td>-0.397</td>\n",
              "      <td>-0.324</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.257</td>\n",
              "      <td>0.378</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>0.079</td>\n",
              "      <td>-0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>water</td>\n",
              "      <td>-0.082</td>\n",
              "      <td>0.107</td>\n",
              "      <td>-0.257</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.658</td>\n",
              "      <td>-0.182</td>\n",
              "      <td>-0.451</td>\n",
              "      <td>0.17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>superplasticizer</td>\n",
              "      <td>0.092</td>\n",
              "      <td>0.043</td>\n",
              "      <td>0.378</td>\n",
              "      <td>-0.658</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.266</td>\n",
              "      <td>0.223</td>\n",
              "      <td>-0.048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>coarseaggregate</td>\n",
              "      <td>-0.109</td>\n",
              "      <td>-0.284</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.182</td>\n",
              "      <td>-0.266</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.178</td>\n",
              "      <td>-0.038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>fineaggregate</td>\n",
              "      <td>-0.223</td>\n",
              "      <td>-0.282</td>\n",
              "      <td>0.079</td>\n",
              "      <td>-0.451</td>\n",
              "      <td>0.223</td>\n",
              "      <td>-0.178</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>age</td>\n",
              "      <td>0.003</td>\n",
              "      <td>-0.021</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>0.17</td>\n",
              "      <td>-0.048</td>\n",
              "      <td>-0.038</td>\n",
              "      <td>-0.115</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ff6531e9-59ae-4cee-b7f0-cf6f69fda985')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ff6531e9-59ae-4cee-b7f0-cf6f69fda985 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ff6531e9-59ae-4cee-b7f0-cf6f69fda985');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.regression import *\n",
        "from pyspark.ml.evaluation import *\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
      ],
      "metadata": {
        "id": "5yyoH3pBalkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def RegressTrainEval(regressor, input_columns, train, test):\n",
        "\n",
        "    def FindMtype(regressor):\n",
        "        # Intstantiate Model\n",
        "        M = regressor\n",
        "        # Learn what it is\n",
        "        Mtype = type(M).__name__\n",
        "        \n",
        "        return Mtype\n",
        "    \n",
        "    Mtype = FindMtype(regressor)\n",
        "#     print('\\033[1m' + Mtype + ':' + '\\033[0m')\n",
        "\n",
        "\n",
        "    if Mtype == \"LinearRegression\":\n",
        "        \n",
        "        #first without cross val\n",
        "        fitModel = regressor.fit(train)\n",
        "\n",
        "        # Load the Summary\n",
        "        trainingSummary = fitModel.summary\n",
        "        \n",
        "        # Print the coefficients and intercept for linear regression\n",
        "        print('\\033[1m' + \"Linear Regression Model Training Summary without cross validation:\"+ '\\033[0m')\n",
        "        print(\" \")\n",
        "        print(\"Intercept: %s\" % str(fitModel.intercept))\n",
        "        print(\"\")\n",
        "        print(\"Coefficients: \")\n",
        "        coeff_array = fitModel.coefficients.toArray()\n",
        "        # Convert from numpy array to list\n",
        "        coeff_list = []\n",
        "        for x in coeff_array:\n",
        "            coeff_list.append(float(x))\n",
        "        result = spark.createDataFrame(zip(input_columns,coeff_list), schema=['feature','coeff'])\n",
        "        print(result.orderBy(result[\"coeff\"].desc()).show(truncate=False))\n",
        "\n",
        "\n",
        "\n",
        "        # Summarize the model over the training set and print out some metrics\n",
        "        print(\"numIterations: %d\" % trainingSummary.totalIterations)\n",
        "        print(\"objectiveHistory: (scaled loss + regularization) at each iteration \\n %s\" % str(trainingSummary.objectiveHistory))\n",
        "        print(\"\")\n",
        "        \n",
        "        # Print the Errors\n",
        "        print(\"Training RMSE: %f\" % trainingSummary.rootMeanSquaredError)\n",
        "        print(\"Training r2: %f\" % trainingSummary.r2)\n",
        "        print(\"\")\n",
        "        \n",
        "\n",
        "        # Now load the test results\n",
        "        test_results = fitModel.evaluate(test)\n",
        "\n",
        "        # And print them\n",
        "        print(\"Test RMSE: {}\".format(test_results.rootMeanSquaredError))\n",
        "        print(\"Test r2: {}\".format(test_results.r2))\n",
        "        print(\"\")\n",
        "        \n",
        "        #Now train with cross val\n",
        "        paramGrid = (ParamGridBuilder() \\\n",
        "#              .addGrid(regressor.maxIter, [10, 15]) \\\n",
        "             .addGrid(regressor.regParam, [0.1, 0.01]) \\\n",
        "             .build())\n",
        "        \n",
        "        #Evaluator\n",
        "        revaluator = RegressionEvaluator(metricName=\"rmse\")\n",
        "        \n",
        "        #Cross Validator requires all of the following parameters:\n",
        "        crossval = CrossValidator(estimator=regressor,\n",
        "                                  estimatorParamMaps=paramGrid,\n",
        "                                  evaluator=revaluator,\n",
        "                                  numFolds=2) # 3 is best practice\n",
        "        \n",
        "        print('\\033[1m' + \"Linear Regression Model Summary WITH cross validation:\"+ '\\033[0m')\n",
        "        print(\" \")\n",
        "        # Run cross validations\n",
        "        fitModel = crossval.fit(train)\n",
        "        \n",
        "        #save model\n",
        "        global LR_BestModel \n",
        "        LR_BestModel = fitModel.bestModel\n",
        "        \n",
        "        print(\"Coefficients: \")\n",
        "        coeff_array = LR_BestModel.coefficients.toArray()\n",
        "        # Convert from numpy array to list\n",
        "        coeff_list = []\n",
        "        for x in coeff_array:\n",
        "            coeff_list.append(float(x))\n",
        "        result = spark.createDataFrame(zip(input_columns,coeff_list), schema=['feature','coeff'])\n",
        "        print(result.orderBy(result[\"coeff\"].desc()).show(truncate=False))\n",
        "        \n",
        "        # Get Model Summary Statistics\n",
        "        ModelSummary = fitModel.bestModel.summary\n",
        "        \n",
        "        print(\"Coefficient Standard Errors: \")\n",
        "        coeff_ste = ModelSummary.coefficientStandardErrors\n",
        "        result = spark.createDataFrame(zip(input_columns,coeff_ste), schema=['feature','coeff std error'])\n",
        "        print(result.orderBy(result[\"coeff std error\"].desc()).show(truncate=False))\n",
        "        print(\" \")\n",
        "        print(\"P Values: \") \n",
        "        # Then zip with input_columns list and create a df\n",
        "        pvalues = ModelSummary.pValues\n",
        "        result = spark.createDataFrame(zip(input_columns,pvalues), schema=['feature','P-Value'])\n",
        "        print(result.orderBy(result[\"P-Value\"].desc()).show(truncate=False))\n",
        "        print(\" \")\n",
        "        \n",
        "        # Use test set here so we can measure the accuracy of our model on new data\n",
        "        ModelPredictions = fitModel.transform(test)\n",
        "        \n",
        "        # cvModel uses the best model found from the Cross Validation\n",
        "        # Evaluate best model\n",
        "        test_results = revaluator.evaluate(ModelPredictions)\n",
        "        print('RMSE:', test_results)\n",
        "    \n",
        "        # Set the column names to match the external results dataframe that we will join with later:\n",
        "        columns = ['Regressor', 'Result']\n",
        "        \n",
        "        # Format results and return\n",
        "        rmse_str = [str(test_results)] #make this a string and convert to a list\n",
        "        Mtype = [Mtype] #make this a string\n",
        "        result = spark.createDataFrame(zip(Mtype,rmse_str), schema=columns)\n",
        "        result = result.withColumn('Result',result.Result.substr(0, 5))\n",
        "        return result\n",
        "\n",
        "    else:\n",
        "\n",
        "        # Add parameters of your choice here:\n",
        "        if Mtype in(\"RandomForestRegressor\"):\n",
        "            paramGrid = (ParamGridBuilder() \\\n",
        "#                            .addGrid(regressor.maxDepth, [2, 5, 10])\n",
        "#                            .addGrid(regressor.maxBins, [5, 10, 20])\n",
        "                           .addGrid(regressor.numTrees, [5, 20])\n",
        "                         .build())\n",
        "\n",
        "        # Add parameters of your choice here:\n",
        "        if Mtype in(\"GBTRegressor\"):\n",
        "            paramGrid = (ParamGridBuilder() \\\n",
        "#                          .addGrid(regressor.maxDepth, [2, 5, 10, 20, 30]) \\\n",
        "                         .addGrid(regressor.maxBins, [10, 20]) \\\n",
        "                         .addGrid(regressor.maxIter, [10, 15])\n",
        "                         .build())\n",
        "\n",
        "        # Add parameters of your choice here:\n",
        "        if Mtype in(\"DecisionTreeRegressor\"):\n",
        "            paramGrid = (ParamGridBuilder() \\\n",
        "#                          .addGrid(regressor.maxDepth, [2, 5, 10, 20, 30]) \\\n",
        "                         .addGrid(regressor.maxBins, [10, 20, 40]) \\\n",
        "                         .build())\n",
        "\n",
        "        #Cross Validator requires all of the following parameters:\n",
        "        crossval = CrossValidator(estimator=regressor,\n",
        "                                  estimatorParamMaps=paramGrid,\n",
        "                                  evaluator=RegressionEvaluator(metricName=\"rmse\"),\n",
        "                                  numFolds=2) # 3 is best practice\n",
        "        # Fit Model: Run cross-validation, and choose the best set of parameters.\n",
        "        fitModel = crossval.fit(train)\n",
        "        \n",
        "        # Get Best Model\n",
        "        BestModel = fitModel.bestModel\n",
        "\n",
        "        # FEATURE IMPORTANCES\n",
        "        # Estimate of the importance of each feature.\n",
        "        # Each feature’s importance is the average of its importance across all trees \n",
        "        # in the ensemble The importance vector is normalized to sum to 1. \n",
        "        print(\" \")\n",
        "        print('\\033[1m' + Mtype,\" Feature Importances\"+ '\\033[0m')\n",
        "        print(\"(Scores add up to 1)\")\n",
        "        print(\"Lowest score is the least important\")\n",
        "        print(\" \")\n",
        "        featureImportances = BestModel.featureImportances.toArray()\n",
        "        # Convert from numpy array to list\n",
        "        imp_scores = []\n",
        "        for x in featureImportances:\n",
        "            imp_scores.append(float(x))\n",
        "        # Then zip with input_columns list and create a df\n",
        "        result = spark.createDataFrame(zip(input_columns,imp_scores), schema=['feature','score'])\n",
        "        print(result.orderBy(result[\"score\"].desc()).show(truncate=False))\n",
        "        \n",
        "        #Create Global Variables for feature importances and models\n",
        "        if Mtype in(\"DecisionTreeRegressor\"):\n",
        "            global DT_featureImportances\n",
        "            DT_featureImportances = BestModel.featureImportances.toArray()\n",
        "            global DT_BestModel \n",
        "            DT_BestModel = fitModel.bestModel\n",
        "        if Mtype in(\"GBTRegressor\"):\n",
        "            global GBT_featureImportances\n",
        "            GBT_featureImportances = BestModel.featureImportances.toArray()\n",
        "            global GBT_BestModel \n",
        "            GBT_BestModel = fitModel.bestModel\n",
        "        if Mtype in(\"RandomForestRegressor\"):\n",
        "            global RF_featureImportances\n",
        "            RF_featureImportances = BestModel.featureImportances.toArray()\n",
        "            global RF_BestModel \n",
        "            RF_BestModel = fitModel.bestModel\n",
        "                    \n",
        "        # Set the column names to match the external results dataframe that we will join with later:\n",
        "        columns = ['Regressor', 'Result']\n",
        "        \n",
        "        # Make predictions.\n",
        "        predictions = fitModel.transform(test)\n",
        "        # Select (prediction, true label) and compute test error\n",
        "        evaluator = RegressionEvaluator(metricName=\"rmse\")\n",
        "        rmse = evaluator.evaluate(predictions)\n",
        "        rmse_str = [str(rmse)] #make this a string and convert to a list\n",
        "        Mtype = [Mtype] #make this a string\n",
        "        result = spark.createDataFrame(zip(Mtype,rmse_str), schema=columns)\n",
        "        # Clean up the Result column and output\n",
        "        result = result.withColumn('Result',result.Result.substr(0, 5))\n",
        "        return result"
      ],
      "metadata": {
        "id": "qV2nnoEibi6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = final_data.randomSplit([0.8,0.2], seed = 42)"
      ],
      "metadata": {
        "id": "Irnk5wwdcP6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run!\n",
        "regressors = [\n",
        "                LinearRegression()\n",
        "                ,DecisionTreeRegressor()\n",
        "                ,RandomForestRegressor()\n",
        "                ,GBTRegressor()\n",
        "                ] \n",
        "    \n",
        "#set up your results table\n",
        "columns = ['Regressor', 'Result']\n",
        "vals = [(\"Place Holder\",\"N/A\")]\n",
        "results = spark.createDataFrame(vals, columns)\n",
        "\n",
        "for regressor in regressors:\n",
        "    new_result = RegressTrainEval(regressor, input_features, train, test)\n",
        "    results = results.union(new_result)\n",
        "results = results.where(\"Regressor!='Place Holder'\")\n",
        "results.show(100,False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jl0gzNZ4brpN",
        "outputId": "1c198550-2696-4264-b36a-baf8e8a4b4fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mLinear Regression Model Training Summary without cross validation:\u001b[0m\n",
            " \n",
            "Intercept: -81.05655173505252\n",
            "\n",
            "Coefficients: \n",
            "+----------------+--------------------+\n",
            "|feature         |coeff               |\n",
            "+----------------+--------------------+\n",
            "|age             |9.280165268295693   |\n",
            "|cement          |0.1370268695283401  |\n",
            "|superplasticizer|0.1285671310138974  |\n",
            "|slag            |0.11899568096469178 |\n",
            "|flyash          |0.0949607105842436  |\n",
            "|fineaggregate   |0.03450929428975515 |\n",
            "|coarseaggregate |0.030122958098980544|\n",
            "|water           |-0.1235148404510801 |\n",
            "+----------------+--------------------+\n",
            "\n",
            "None\n",
            "numIterations: 0\n",
            "objectiveHistory: (scaled loss + regularization) at each iteration \n",
            " [0.0]\n",
            "\n",
            "Training RMSE: 7.103661\n",
            "Training r2: 0.821990\n",
            "\n",
            "Test RMSE: 7.555857566977418\n",
            "Test r2: 0.7764061507411935\n",
            "\n",
            "\u001b[1mLinear Regression Model Summary WITH cross validation:\u001b[0m\n",
            " \n",
            "Coefficients: \n",
            "+----------------+--------------------+\n",
            "|feature         |coeff               |\n",
            "+----------------+--------------------+\n",
            "|age             |9.270392898571005   |\n",
            "|cement          |0.13575694453900158 |\n",
            "|superplasticizer|0.12859045324037782 |\n",
            "|slag            |0.11750136723732069 |\n",
            "|flyash          |0.09319412305068252 |\n",
            "|fineaggregate   |0.033051013136789285|\n",
            "|coarseaggregate |0.028922988306573326|\n",
            "|water           |-0.1278162217748891 |\n",
            "+----------------+--------------------+\n",
            "\n",
            "None\n",
            "Coefficient Standard Errors: \n",
            "+----------------+--------------------+\n",
            "|feature         |coeff std error     |\n",
            "+----------------+--------------------+\n",
            "|age             |0.22472893025358054 |\n",
            "|superplasticizer|0.0703048718547792  |\n",
            "|water           |0.030193785145445334|\n",
            "|flyash          |0.009306614349746944|\n",
            "|fineaggregate   |0.008009802877026602|\n",
            "|slag            |0.007615188052570103|\n",
            "|coarseaggregate |0.00719361890961445 |\n",
            "|cement          |0.006380286271499102|\n",
            "+----------------+--------------------+\n",
            "\n",
            "None\n",
            " \n",
            "P Values: \n",
            "+----------------+--------------------+\n",
            "|feature         |P-Value             |\n",
            "+----------------+--------------------+\n",
            "|superplasticizer|0.06774377094113326 |\n",
            "|coarseaggregate |6.319595311321535E-5|\n",
            "|fineaggregate   |4.048881991058906E-5|\n",
            "|water           |2.554837522383835E-5|\n",
            "|cement          |0.0                 |\n",
            "|flyash          |0.0                 |\n",
            "|slag            |0.0                 |\n",
            "|age             |0.0                 |\n",
            "+----------------+--------------------+\n",
            "\n",
            "None\n",
            " \n",
            "RMSE: 7.552339163757074\n",
            " \n",
            "\u001b[1mDecisionTreeRegressor  Feature Importances\u001b[0m\n",
            "(Scores add up to 1)\n",
            "Lowest score is the least important\n",
            " \n",
            "+----------------+--------------------+\n",
            "|feature         |score               |\n",
            "+----------------+--------------------+\n",
            "|age             |0.4066671224646348  |\n",
            "|cement          |0.27479564452553124 |\n",
            "|water           |0.13962137780135578 |\n",
            "|superplasticizer|0.08875878027151377 |\n",
            "|slag            |0.057402079604341114|\n",
            "|flyash          |0.023972913740494   |\n",
            "|fineaggregate   |0.004853329360675258|\n",
            "|coarseaggregate |0.003928752231453982|\n",
            "+----------------+--------------------+\n",
            "\n",
            "None\n",
            " \n",
            "\u001b[1mRandomForestRegressor  Feature Importances\u001b[0m\n",
            "(Scores add up to 1)\n",
            "Lowest score is the least important\n",
            " \n",
            "+----------------+--------------------+\n",
            "|feature         |score               |\n",
            "+----------------+--------------------+\n",
            "|age             |0.3544879662306768  |\n",
            "|cement          |0.2635273555069993  |\n",
            "|water           |0.14992589759821898 |\n",
            "|superplasticizer|0.07279419448784129 |\n",
            "|slag            |0.06171700225250546 |\n",
            "|fineaggregate   |0.037320491305907734|\n",
            "|flyash          |0.03149810096975467 |\n",
            "|coarseaggregate |0.028728991648095597|\n",
            "+----------------+--------------------+\n",
            "\n",
            "None\n",
            " \n",
            "\u001b[1mGBTRegressor  Feature Importances\u001b[0m\n",
            "(Scores add up to 1)\n",
            "Lowest score is the least important\n",
            " \n",
            "+----------------+-------------------+\n",
            "|feature         |score              |\n",
            "+----------------+-------------------+\n",
            "|age             |0.24053026578610825|\n",
            "|cement          |0.18741344372713095|\n",
            "|water           |0.1469923011567656 |\n",
            "|coarseaggregate |0.1013087628182122 |\n",
            "|fineaggregate   |0.09353867232462129|\n",
            "|slag            |0.09189519265196618|\n",
            "|superplasticizer|0.08549656139609534|\n",
            "|flyash          |0.05282480013910015|\n",
            "+----------------+-------------------+\n",
            "\n",
            "None\n",
            "+---------------------+------+\n",
            "|Regressor            |Result|\n",
            "+---------------------+------+\n",
            "|LinearRegression     |7.552 |\n",
            "|DecisionTreeRegressor|9.081 |\n",
            "|RandomForestRegressor|7.377 |\n",
            "|GBTRegressor         |7.369 |\n",
            "+---------------------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results.orderBy(results['Result'].asc()).show(10,False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dostc79VciAV",
        "outputId": "751d1b2c-fce8-4877-c3ce-bd3775629a9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------+------+\n",
            "|Regressor            |Result|\n",
            "+---------------------+------+\n",
            "|GBTRegressor         |7.369 |\n",
            "|RandomForestRegressor|7.377 |\n",
            "|LinearRegression     |7.552 |\n",
            "|DecisionTreeRegressor|9.081 |\n",
            "+---------------------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "it looks like that Gradiant Boosting tree algorithm performs the best and yield the least error\n",
        "\n",
        "thus will use it in next predictions"
      ],
      "metadata": {
        "id": "t8RrjOycs28p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Its also clear that almost all the models agree that the most 3 important features in cement strength are cement, age and water"
      ],
      "metadata": {
        "id": "wHCI-BUn1ra7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "testing_data = [540,0,0,162,2.5,1040,676,28]\n",
        "testing_data = spark.createDataFrame(data = [testing_data] , schema = input_features)\n",
        "testing_data = assembler.transform(testing_data).select('features')\n",
        "testing_data.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r94LTvahdL6L",
        "outputId": "aaa11d30-6957-4044-f98c-65fe8ea13a4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|            features|\n",
            "+--------------------+\n",
            "|[540.0,0.0,0.0,16...|\n",
            "+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "infer = GBT_BestModel.transform(testing_data)\n",
        "pred = infer.select('prediction').limit(1).collect()[0][0]\n",
        "print(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sflc2qS2mjG3",
        "outputId": "284dc027-aa74-4fc8-b5d7-c4c492ae0ef5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "82.84264141141634\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "take the age as a user input"
      ],
      "metadata": {
        "id": "7byROCrWtH_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "age = int(input('Enter the age: '))\n",
        "testing_data = [540,0,0,162,2.5,1040,676,age]\n",
        "testing_data = spark.createDataFrame(data = [testing_data] , schema = input_features)\n",
        "testing_data = assembler.transform(testing_data).select('features')\n",
        "infer = GBT_BestModel.transform(testing_data)\n",
        "pred = infer.select('prediction').limit(1).collect()[0][0]\n",
        "print('Predicted cement strength value with these specified features is ',pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VRX-RbbqcEZ",
        "outputId": "5cbc6024-6622-472e-d105-85ee67371126"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the age: 80\n",
            "Predicted cement strength value with these specified features is  82.84264141141634\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testing_data.show(1, False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lC3SPAICtO9k",
        "outputId": "744799de-1a66-4174-e089-5e8893044b92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------------------+\n",
            "|features                                  |\n",
            "+------------------------------------------+\n",
            "|[540.0,0.0,0.0,162.0,2.5,1040.0,676.0,5.0]|\n",
            "+------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ny3o9poMvMAI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}